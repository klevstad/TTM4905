\chapter{Background and Related Work}
\label{chp:background}

\section{Internet of Things}
\label{sec:iot}

Over the last decade, a concept called the \emph{Internet of Things} has gained increased attention, both from the research community and commercial actors, as well as consumers. The term \gls{iot} was, accordingly to most sources, coined in 1999 by the British visionary Kevin Ashton in a presentation about \gls{rfid} \cite{iot-phrase-2, iot-phrase-1}. Ashton's definition of the concept was a world where computers do not depend on human beings to provide them with information. Out of all the petabytes of information available on the Internet, the majority has been created and captured by humans performing some sort of action. In his opinion, \gls{iot} is about providing computers with the ability to gather information on their own.

Computational devices that contain some sort of sensor may be attached to your everyday physical device, for example your potted plant. This creates a bridge between our physical world and the cyber world \cite{Kopetz2011}. The connection to the Internet allows us to monitor and control these devices and sensors from a remote distance. Another vital part of \gls{iot} is device-to-device communications, essentially enabling devices to communicate with each other without human aid, and exchange and retrieve information. Such devices could be sensors monitoring an operation, a physical area, or even attached to a physical body. The possibilities are more or less unlimited. Imagine a home automation and surveillance system for your cabin, where lights, heaters, smoke detectors, underfloor heating, motion detectors, security cameras, garage, and so on, are all interconnected with each other through small wireless devices. As it is called the \emph{Internet} of Things for a reason, your system and devices would be accessible over the Internet, allowing you to monitor the current status of your cabin remotely from your couch at home, as well as looking at historical data of the different sensors and devices. When the weekend arrives and you head for the mountains, the \gls{iot} provides you with an opportunity to preheat different (or all) sections of the cabin, deactivate the alarm, and perhaps instruct the sauna to start getting cosy. 


Another approach is to avoid using a monitor to remotely control the system, and instead allowing the system to observe and act on your behaviour. We want the devices to know us and figure out the correct decision to make without us telling them. For example, when pulling your car into the driveway, you want the garage door that is connected with your car to open up. The garage notifies your front door that you are home, which conveniently unlocks and notifies your house to turn on the lights in your hallway and perhaps the heater in your living room.



The possibilities that are revealed as the \gls{iot} grows larger and the services expand are endless. The concept is highly applicable for different scenarios involving home automation, standalone consumer products, industrial and environmental facilities, as well as medical surveillance. While larger automation systems for homes and facilities have been the target for the research community and early adopters, the consumer market has been focused on so-called \emph{wearables}. Wearables are fundamentally devices that you wear, such as smart watches, fitness trackers, virtual reality glasses, headphones, and smart clothing. Such human-centric devices are less about automation, and more focused on personal improvement. Nevertheless, the increase in \gls{iot} devices possibly provides us with a more cost efficient future, both in our use of time, as well as energy and consumption of other resources.


% Security challenges
As the \gls{iot} is built upon the Internet, it faces the same types of security issues as the Internet itself. The amount of ``things'' connected to the Internet is calculated to be 6.4 billions by the end of 2016, which is almost a 30\% increase from 2015 \cite{iot-gartner}. By 2020, the expected number of these ``things'' is more than 20 billion, providing attackers with equally many possible devices to attack. Given the knowledge that some of these devices may be medical (or have other sensitive applications), we quickly recognize potential catastrophic scenarios.


The \gls{iot} architecture can resemble the neural system of the human body. The perception layer controls our sensors which we use to obtain information about our environment by observing, feeling, smelling, tasting, or hearing. As previously described, \gls{iot} devices are often deployed with one or more sensors to perform these ``human operations'' for information collection. The perception layer is mainly focusing on sensing and allowing \gls{iot} devices to observe their environment and collect information. Examples of such technologies are \gls{rfid}, \gls{wsn}, and the \gls{gps} \citep{Jing2014}. Information from our human sensors are carried to the brain through a neural network. Much alike in \gls{iot}, the collected information is transmitted using the transportation layer. The transportation layer is running over some wireless or wired medium such as 802.15.4, \gls{6lowpan}, 3G, Bluetooth or Infrared. Finally the information is processed by an intelligent entity. In our human body, that would be the brain. In the \gls{iot}, the brain would be an intelligent processing unit in the application layer which is able to compute and analyse actions based on the received information \cite{iot-layers2012, iot-layers2010}. The application layer is also responsible for controlling the sensors, performing global system management, and present data for the end users of the system.


As these layers covers different characteristics of \gls{iot}, they consists of different types of hardware and provide different types of services, hence they are subject to different types of security threats and solutions. The most adjacent problems to the scope of this thesis are the problems related to key establishment and key management, which define how two devices safely can establish secure communication between each other. Or in other words, how collected information is safely transmitted between the sensors and the ``brain''. 

%The \gls{iot} architecture is divided into three layers: perception, transportation and application, each addressing different types of security \cite{Jing2014}. Transportation and application layers, however, are out of scope for this project. The perception layer is mostly about sensors and other nodes that collect information from their environment, and communicate it throughout the transport network. Another goal for the layer is to pass control messages received. Examples of such technologies are \gls{rfid}, \gls{wsn}, and the \gls{gps}, each dealing with their own security problems and solutions. 



In an \gls{iot} world, the protection of data and privacy is an essential part. As previously mentioned, \gls{iot} technology may be a solution for problems involving sensitive information. In a medical facility, a possible scenario could be a \gls{wsn}, which is a dynamic and bi-directional network of nodes where each node has one or more sensors connected to it. A patient may have sensors implanted in their body, as well as different instruments attached for measuring different properties. All these devices communicate with each other wirelessly, and the network is therefore a possible target for an attacker. To prevent the attacker from eavesdropping, and possible forging content in the network, encryption and authentication at the different nodes is crucial.



% More motivation for the need for key management/establishment in \gls{iot}?


% Authentication. Encryption. 



\section{The IEEE 802.15.4 Standard}
\label{sec:802154}

Following the evolution of \gls{iot}, the need for cheap devices to communicate efficiently between each other has arisen. Existing architectures such as 802.11 (WiFi) and Bluetooth are too expensive in terms of processing and energy consumption, as the idea of \gls{iot} is to connect even the smallest devices to a network or Internet. As these devices are small, they have a limited battery life, and need to use energy in a highly efficient matter.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.55]{osi.png}
	\caption{The OSI stack with layers, the data they carry, and example of technology running at the different layers.}
	\label{fig:osi}
\end{figure}

Protocols using the \gls{ieee} 802.15.4 standard are envisioned for applications supporting smart homes, medical surveillance, monitoring systems for environmental and industrial systems, as well as sensor systems for heating and ventilation. As we know from the \gls{iot}, it is really the imagination that puts an end to the possibilities for interconnected devices. The \gls{ieee} 802.15.4 standard only defines the physical and data link layer of the \gls{osi} stack, which can be seen in Figure \ref{fig:osi}. Therefore, specifications need to be developed to utilize the possibilities provided by 802.15.4 in the upper layers. ZigBee \cite{zigbee}, maintained by the ZigBee Alliance, is the most notable example of specifications that uses 802.15.4 as its base. Others include WirelessHART \citep{wirelesshart}, MiWi \cite{miwi}, and ISA100.11a \cite{isa100}.

The fundamental intention of the 802.15.4 standard is to provide low-rate, low-power communication between devices within a sensor network or \gls{wpan}. Its main use case is to let multiple devices within a short range communicate with each other over a low-rate radio, while maintaining a modest energy consumption. Figure \ref{fig:802154-figure} paints a picture of what 802.15.4 is, compared to more well-established concepts such as WiFi (802.11) and Bluetooth, focusing on energy consumption, complexity and date rate. While being smaller and more cost efficient than those found in more complex networks, devices that operates in 802.15.4 networks have a much more limited range (about 10 meters), and in most cases a throughput below 250 Kbps \cite{gutierrez2001ieee}. Not only is the 802.15.4 standard significantly lighter in terms of data rate and power consumption, it is also aimed at a different market than regular \gls{wpan}s. \gls{wpan}s are oriented around a person, creating a personal network for the user, which has higher demands to data rate, and can allow a higher energy consumption. 802.15.4, however, focuses on interconnecting devices that do not necessary have this constraint, such as industrial and medical applications. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{802154.png}
	\caption{Figure of IEEE 802.15.4's operational space compared to other wireless standards \cite{gutierrez2001ieee}.}
	\label{fig:802154-figure}
\end{figure}

Four basic security services are provided in the 802.15.4 link-layer security package, namely access control, message integrity, message confidentiality, and replay protection (sequential freshness) \cite{sastry2004security}. The \gls{ieee} 802.15.4 standard is delivered with a total of eight different security suites, providing none, some, or all of the described security services, and it is up to the application designer to specify and enable the desired security properties. In the most secure end of the scale we find the \gls{aes}-\gls{ccm}, which is encryption using the block cipher \gls{aes} with either a 32, 64 or 128-bit \gls{mac-auth}. Such a suite provides both strong encryption and possibly unforgeable messages (a 64-bit \gls{mac-auth} gives an adversary a $2^{-64}$ chance of successfully forging a message, and is used to enable legitimate nodes in the network to detect if a received message have been tampered with). On the other end of the scale we find a suite providing only confidentiality using \gls{aes} in \gls{ctr} mode. This suite does not, however, provide any form of authentication -- giving adversaries the possibility to forge messages. One of the things that the 802.15.4 standard does not specify, however, is how to deal with key establishment and key management. Therefore, these issues have to be taken care of in the higher layers.


\section{6LoWPAN: Putting IP on Top of 802.15.4}
\label{sec:6lowpan}

% We want to reach our devices over the Internet. IP is the thing.

Initially, the \gls{ip} was considered to be too ``heavy'' for low-power wireless networks such as the ones described by the 802.15.4 standard. The idea of implementing \gls{ip} on top of 802.15.4 networks was born as early as 2001 under the question ``Why invent a new protocol when we already have IP?'' \cite{Mulligan2007}. With \gls{ip}, the community already had a bundle of existing protocols for management, transport, configuring and debugging, such as \gls{snmp}, \gls{tcp} and \gls{udp}, as well as standardized services for higher layers such as caching, firewalls, load balancing, and mobility. Nevertheless, the initial idea of using \gls{ip} in combination with sensor networks or \gls{wpan}s was not accepted by various groups such as ZigBee \cite{Mulligan2007}. The rejection did not, however, stop the initiative, and a group of engineers within the \gls{ietf} started designing and developing what would later be known as \gls{6lowpan}.

One of the significant advantages with combining \gls{ip} and 802.15.4 is the simplification of the connectivity model between various devices in the networks. As most 802.15.4-based specifications usually need custom hardware that tends to be complex, the possibilities to interconnect different networks with each other is somewhat limited. By turning to \gls{ip}, the need for complex connectivity models is obsolete as it is possible to use well-understood technologies such as bridges and routers. Another advantage with using \gls{ip} is that the routers between the \gls{6lowpan} devices and the outside networks (so-called edge routers) do not need to maintain any state of the devices within a \gls{6lowpan}, as they are merely forwarding datagrams.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{6lowpan.png}
	\caption{Figure of the 6LoWPAN stack, which uses the IEEE 802.15.4 physical and link layer, but adds its own adoption layer at the network layer.}
	\label{fig:6lowpan-stack}
\end{figure}

\gls{6lowpan} enables wireless 802.15.4 sensor devices to connect directly to the Internet via \gls{ip}v6 by providing an adoption layer at the network layer as shown in Figure \ref{fig:6lowpan-stack}. The adoption layer provides unique functionality that fragments and compresses incoming packets to minimize header and packet size. This enables the embedded devices in 802.15.4 networks to receive the packets while using the least amount of memory and energy \cite{krentz20136lowpan}. Its fundamental idea is that you only would only have to ``pay'' for what you use. The dispatch header field identifies the type of header to follow, and consists of 1 byte \citep{Mulligan2007}. Such a header starts with either 00 or 01, respectively indicating whether the frame is a non-\gls{6lowpan} frame or a regular \gls{6lowpan}-frame. Currently, only five different dispatch headers have been defined \cite{rfc6282}. In the special case of where a header consists solely of ones, an additional byte is added to the header, enabling a total of 320 different header types \citep{Mulligan2007}. This greatly differs from \gls{ip}v4 and Zigbee, which only define one monotonic header. The use of different headers can be used to greatly minimize the header size of a packet as some types of frames may consist of smaller payloads than others, and where some header fields may be obsolete for the purpose of the frame.


Compared to other alternatives such as ZigBee or Z-wave, \gls{6lowpan}'s implementation did not prove to be any more expensive in terms of code size and \gls{ram} requirements. \gls{6lowpan} seems to be a natural choice for the future \gls{iot} as a networking protocol. It is scalable thanks to \gls{ip}v6, and its headers can be compressed to only a few bytes using its fragmentation and compression mechanism. Following the expected bloom in \gls{iot} devices over the next few years (20 billion by 2020), and the fact that the \gls{ip}v6 address space is not going to be exhausted any time soon (roughly $2^{95}$ addresses for each and every one of us), \gls{6lowpan} may be the most reasonable approach.

\section{Key Establishment and Key Management}
\label{sec:keyestablishment}

As described, \gls{iot} devices communicate with each other over a network by utilizing some network protocol. There is, however, not always a guarantee that the network used for communication is secure. An attacker may be eavesdropping on the network, and may even be capable of intercepting and spoofing traffic sent between different nodes. From a security perspective, the described attacker is violating both the confidentiality and integrity of the exchanged information. To cope with this, devices should be encrypting and authenticating the data that they are exchanging. 


Key establishment is a fundamental idea in cryptography where two (or more) communicating parties exchange information in order to generate cryptographic keys which would enable them to perform cryptography (i.e. encryption, decryption, authentication) on the messages that are sent between them. The problem is, however, how to safely agree upon the keys to use in the encryption-decryption process when the network itself cannot be trusted. For \gls{iot} devices and sensor networks, confidentiality and data integrity are important aspects. As previously described, \gls{iot} devices have limited resources in terms of battery life and processing abilities. This makes key establishment schemes that work well in other networks with access to more resources, such as WiFi, infeasible in an \gls{iot} scenario.


\subsection{Long-Term and Session Keys}


\subsubsection{Long-Term keys}

Long-term keys are keys that are deliberately stored on a device, as they are used multiple times for securing communication, and have no ``expiration date''. The shared secret key in symmetric key encryption, and the private key in public-key cryptography are examples of long-term keys.


\subsubsection{Session Keys}

Session keys are temporary keys that are used for a short period of time. By using such keys, the amount of ciphertexts encrypted with the same key is limited for an adversary to perform cryptanalysis on. Another advantage with using session keys is in the case of a node being compromised. If the protocol provides forward secrecy and known-key security (which will be described in Section \ref{sec:attributes}), the data that is compromised is limited to that particular session. Session keys are not permanently stored at the client, and usually deleted after its expiration time, limiting the cost of memory, and distancing it from leaking previous session keys in the case of being compromised.



\subsection{Security Attributes in Key Establishment Schemes}
\label{sec:attributes}


\subsubsection{Authentication}

Authentication is an important aspect of key establishment. More specifically, confirming the identity of the entity you are establishing keys with, as well as confirming that the established keys are authentic. If authentication is skipped, the protocol can be weak to so-called man-in-the-middle attacks where an adversary intercepts and relays messages between two communicating parties to learn or modify its content. There are multiple ways for parties to provide authentication based on the chosen key establishment scheme. For symmetric schemes, the inclusion of a \gls{mac-auth} could provide authentication of the identity of the origin of a message. Schemes using public-key provides authentication through digital certificates, which are issued by a \gls{ca}, and ensure the link between an identity and a public key.

For session keys, two properties are introduced, namely \emph{implicit key authentication} and \emph{explicit key authentication}. One of the most used ways of establishing session keys between two entities $A$ and $B$ is through $A$ generating a random symmetric key, which is encrypted under $B$'s public key, before it is transmitted. $B$ is then able to extract the session key that should be used for encrypting data using his private key. \emph{Implicit key authentication} assures that only the rightful owner of the public key, which the session key is encrypted under (in this case $B$), is able to recover the session key. It does not, however, assure that $B$ is in fact possessing the session key \cite{hankerson2006guide}. If the protocol also assures $A$ that $B$ has received and possesses the session key, the protocol provides a property called \emph{key confirmation}. If a protocol provides both implicit key authentication and key confirmation, we say that the protocol overall provides \emph{explicit key authentication}. As a side note, exactly how to define explicit key authentication is in some sense based on the glass half-full half-empty paradox. Is the knowledge of that the other party possesses everything it needs to derive the shared key enough for confirmation, or is explicit key authentication to actually obtain something signed or encrypted using the pairwise key that you have derived. For this thesis, we will stick to the latter one as our definition of explicit key authentication. 


\subsubsection{Known-Key Security}
% Check

Session keys are single-use symmetric keys that are used for a given period of the communication before being replaced and deleted from the system, never to be used again. Known-key security is a property where the leak of information is minimized in the case of one (or multiple) session keys are compromised. For example in the case where session keys are derived from the private key, then the compromise should not lead to the compromise of the private key, nor any of the past or future session keys. 

\subsubsection{Perfect Forward Secrecy}
% Check

Following in the lines of known-key security, \gls{pfs} is a security attribute where in the case of the long-term private key of one (or both) of the communicating parties being compromised, it should not lead to the reveal of any of the past session keys that are used in the communication between the parties. The Heartbleed incident in 2014 was a painful example of the need for \gls{pfs}, where a bug in the OpenSSL cryptographic software library leaked secret keys for certificates, as well as user names and passwords \cite{durumeric2014matter}. Attackers were able to retrieve 64 kilobytes of the memory of web servers for each attack (or ``heartbeat''), which could be used to retrieve the private long-term keys of the web servers which did not support forward secrecy. The private keys could then be used to retroactively decrypt almost all traffic that had previously been recorded. One exception was servers that were utilizing one of \gls{tls}'s ephemeral modes, which are based on the Diffie-Hellman key exchange. The great advantage with the Diffie-Hellman key exchange is that it can be used to provide forward secrecy, making web servers that was using such versions of \gls{tls} immune against the attacks that exploited the Heartbleed bug.


% Not _all_ traffic. Ephermal DH potentially Okay.

\gls{pfs} is a desirable security property for key establishment protocols, but it is often difficult to achieve. \gls{wpfs} is a weaker type of \gls{pfs}, where the adversary is assumed to be \emph{passive} \cite{krawczyk2005hmqv}. In the case of a long-term key compromise, previous sessions are guaranteed to be secure, but only if the adversary was not actively interfering with the protocol during the session.  As \gls{pfs} is a property related to session keys, it is not an achievable property for symmetric key schemes.

\subsubsection{Key-Compromise Impersonation}

In this case, an adversary has obtained the long-term private key of an honest entity $A$. \gls{kci} prevents the adversary both from impersonating $A$ to other entities (establishing session keys with them), as well as preventing the adversary from impersonating other entities in communication with $A$ (masquerading as a different entity in order to establish a session key with $A$). \gls{kci} is, however, a very difficult security property to achieve for symmetric key protocols.


% Cite boyd book?
%In practice, a party possessing the private key of $A$ is able to decrypt both past and future traffic going to and from $A$.

% Past. Feil? NA + FS

\subsubsection{Key Control}
% Check

Key control is to prevent a party from computing a part of the session key without input from the other party. Essentially, one of the communicating parties should not be able to force the secret key into something of its own choice. Key control is usually accomplished through both parties creating a random value, which is shared with the other party, and computed together into the shared key, for example in the Diffie-Hellman key exchange.

\subsubsection{Unknown Key-Share}
%Check

Unknown key-share resilience is an attribute in key agreement protocols where a key shared between two entities $A$ and $B$ can not be shared with any others without both consenting to it. When $A$ and $B$ are establishing a shared key, attacks targeting this process may want to convince $A$ that it is sharing the key with $B$, while $B$ in fact is under the impression that it is sharing the key with a third entity $C$. After the key establishment process is finished, $A$ believes it has established a key with $B$ (which is correct), but $B$ is under the belief that it has established a key with $C$. This results in that when $B$ thinks it is sending a message to C, $A$ is the actual receiver of the message.



\subsection{Key Establishment Architectures}

\subsubsection{Symmetric Key}

% Symmetric key
Symmetric encryption is a technique for encrypting messages sent between two communicating parties, where the secret key used for encrypting the message is identical to the key used for decrypting it, as seen in Figure \ref{fig:symmetric}. Plaintext messages are processed through either a stream cipher, which encrypts the message byte by byte, or through a block cipher, which operates on a certain number of bits of the message for each round. The encryption process results in an encrypted message called a ciphertext. In schemes utilizing this form of encryption, it is essential that both parties possesses the same shared secret (or key). One approach to provide both parties with the secret key is to load it into each of the parties in advance, which is inconvenient and difficult approach for a network where nodes may be joining and leaving after network deployment. The most reasonable approach would be for two nodes to agree upon the shared secret together in a possibly unsafe environment.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{symmetric.png}
	\caption{Figure of a symmetric encryption scheme, where both parties possess the same symmetric key used for encryption and decryption.}
	\label{fig:symmetric}
\end{figure}

In the 1970s, Whitfield Diffie and Martin Hellman introduced the Diffie-Hellman key exchange, which allows two communicating parties to safely establish a shared secret without any prior knowledge of each other \cite{diffie1976new}. The shared secret could then be used for encrypting and decrypting messages sent between the two parties.  While being a straightforward and fast way of encrypting information, symmetric encryption has a major drawback in the case of when one of the nodes is compromised. Node compromises would lead to an initially secure channel being insecure as the adversary could easily decrypt any message that it intercepts. Also, the sharing of the key is difficult to do in a secure manner. Another disadvantage with symmetric key schemes is the difficulty of authenticating the other party as they both encrypt data using the same key. For systems using symmetric encryption, authentication can be achieved through construction of \gls{mac-auth}s, which are cryptographic values generated from a symmetric key and the plaintext message. This enables the receiver of a message to compute the same \gls{mac-auth} from the decrypted ciphertext and the shared symmetric key, and provides both authenticity of the sender and the integrity of the received message.


\subsubsection{Online Servers and Trusted Third Parties}

By using a client-server architecture, the idea of a symmetric key that is shared between two parties can be extended to also include mutual authentication and session keys. Alice and Bob wants to establish a shared key, but they do not necessary trust each other. However, they both trust Charlie, which vouches for them both and assist them in agreeing upon a shared key to use for communication. This analogy is also used by the Needham-Schroeder Symmetric Key Protocol, which introduces a trusted third party (often called a \gls{kdc}) to generate and distribute a symmetric session key for Alice and Bob. When Alice wants to communicate with Bob, she notifies the server that she wants to establish a session with Bob. The server computes the session key and encrypts it twice, one time using Alice's secret symmetric key, and one time using Bob's. The secret keys of the parties are stored in advance at the server, hence making it a trusted third party.

The server then sends the encrypted session key to Alice. Alice decrypts the key encrypted with her symmetric key, and forwards the other cryptogram to Bob, which decrypts it using his key to obtain the session key. Bob sends Alice a nonce encrypted under the session key to prove to her that he has the session key, which Alice decrypts, performs a simple operation on, re-encrypts it, and sends it back to Bob, proving to him that she possesses the session key as well. However, this version of the Needham-Schroeder protocol is vulnerable to replay attacks, but can be fixed by using timestamps or include random nonces \cite{needham1987authentication}.

The Needham-Schroeder Symmetric Key protocol is the basis for Kerberos, which is a trusted third-party authentication service \cite{neuman1994kerberos}. Kerberos consists of an \gls{as} and a \gls{tgs}, often hosted in the same \gls{kdc}, and an \gls{ss} for providing services to the clients. The authentication model consists of two different credentials: \emph{tickets} and \emph{authenticators}. Tickets are used to securely transmitting the identity of the client between the \gls{as} and the \gls{ss}, and contains information that is used to confirm that the client using the ticket is in fact the same client which it was issued to \cite{steiner1988kerberos}. After generation, a ticket can be used multiple times until it expires. Authenticators are another type of credentials which is created by the client itself, encrypted, and passed along with the tickets sent from the client to ensure that the presented ticket is issued to it. Figure \ref{fig:kerberos} shows the interaction between the different entities in Kerberos, and how the different tickets are passed through the authentication process.

When the client wants to contact another node in the network, it authenticates itself to the \gls{as} by providing the \gls{as} with its identity. The \gls{as} generates a \gls{tgt} and encrypts it under the client's secret key, and challenges the client: ``If you can decrypt it, you are free to use the ticket to try to obtain a server ticket from the \gls{tgs}''. When the \gls{tgs} receives a \gls{tgt}, it first verifies that it is valid, and that the client is authorized to access to requested service. It then responds with a new ticket for the client to provide when requesting a service from the \gls{ss}. The protocol is finalized by the client sending the server ticket to the \gls{ss}, which is verified, before a confirmation message is generated and passed back to the client. If the client is able to successfully verify the confirmation message, the client and server start a session where the server provides the requested service to the client.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{Kerberos.png}
	\caption{Figure of the interaction between the client, the KDC, and the SS in Kerberos.}
	\label{fig:kerberos}
\end{figure}

\subsubsection{Public-Key}

As described in the section above, the Diffie-Hellman key exchange allowed two parties to agree upon a shared secret without any previous knowledge of each other. This laid the basis for public-key (or asymmetric) encryption, which consists of two keys that are generated mathematically: A private key for decryption, and a public key for encryption. In a public-key encryption system, users who want to send a message to Alice encrypt it using Alice's public key, which is published to the public. When Alice receives an encrypted message, she decrypts it using her private key, as seen in Figure \ref{fig:asymmetric}.


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.65]{asymmetric.png}
	\caption{Figure of public-key encryption where a message to Alice is encrypted using her public key, and decrypted with her corresponding private key.}
	\label{fig:asymmetric}
\end{figure}

Compared to symmetric encryption, public-key cryptography is significantly more computationally costly. However, the approach of using a public and private key for communications is more convenient than using symmetric keys. In the case of a node compromise, only one part of the communication is compromised. The adversary has your private key, and decrypt messages sent to you. It can not, however, decrypt messages that you send to the other party as it does not possess the private key of the other party. Public-key cryptography also allows for authentication of the communicating parties by the use digital signatures. Digital signatures are used to prove authenticity of a message, as well as proving that the message has not been modified in transmission.

As mentioned, public-key cryptography is significantly more computational expensive than symmetric encryption, which has led to a hybrid solution where a symmetric session key is established and encrypted under the public key of each recipient. Such an approach reduces the computation time of encryption and decryption, giving a more efficient encryption scheme.

Public-key cryptography often involves certificates, which are used to prove ownership of a public key, and contains information about the identity of the owner, and also the digital signature of the party that has issued that particular certificate (often called a \gls{ca}). When using a certificate, the sender of a message is able to confirm the identity of the recipient, by validating the certificate and the public key. The recipient may have signed the certificate himself, but the most normal approach is to have it signed by a trusted third party, namely a \gls{ca}, which often are companies specializing in signing certificates and acting as a trusted third party.

\subsection{Key Establishment Schemes}

%Within the different key establishment architectures, multiple key establishment schemes exists. Below are the most commonly used covered.
\label{subsec:keys-schems}

\subsubsection{Symmetric Key}

The simplest possible scheme for symmetric key establishment is the network-shared key scheme, where every node in the network possess the same symmetric key which is used for encryption and decryption between all nodes in the network \cite{perrig2004security}. While being easy to set up, a network-shared symmetric key violates all of the security properties previously described. In addition, it leaves the network vulnerable to node compromises as wireless sensor nodes often are deployed in hostile and unattended areas. This results in a network where the compromise of one node is equal to the compromise of the entire network \cite{krentz20136lowpan}. Also, in 802.15.4, the network-shared key scheme is incompatible with replay protection, moving the responsibility of implementing such measures to the higher layers \cite{sastry2004security}.


% Properties violated: Authentication impossible. Known-key security. 

Pairwise keys is a better symmetric key scheme, where each node pair possesses their own symmetric key for communication between them. This, however, leads to higher memory requirements as the node has to store the symmetric key for possibly $N-1$ nodes (called fully pairwise key schemes), where the number of nodes in the network can be high \cite{perrig2004security}. Group keying is another approach where groups of nodes share the same symmetric key. This greatly reduces the memory consumption for the devices, and can provide a mild version of compromise resilience. Unfortunately, group keying is not supported in \gls{ieee} 802.15.4 \cite{sastry2004security}. When using pairwise keys, it is possible to provide a certain level of authentication, hence avoid unknown key-share attacks if implemented correctly, as well as key control, given that the two parties use a key exchange protocol where both are contributing to the key. The other properties, however, are not able to achieve using pairwise key establishment schemes. 

Random pairwise keys is another scheme in the hunt for pairwise key schemes that maintains a modest level of memory consumption. Assume a ``pool'' of all the possible pairwise keys that can be created between the nodes in the network. Each node obtains a certain portion of these keys chosen at random (If A gets the pairwise key to B, B naturally also obtains the key for communicating with node A). By randomly delegating keys for different links between nodes, the idea is that there should be a possible path from A to C with high probability, even if they do not possess the key for direct communication, they are able to establish a multi-hop path between them by using the other nodes in the network \cite{liu2005establishing}. This approach eliminates the need for storing $N-1$ keys in each node, and is also more compromise resilient than pairwise key schemes as the adversary would only obtain a part of the pairwise keys used in the network if it compromises a node. 


\subsubsection{Online Servers and Trusted Third Parties}

As mentioned, Kerberos is the most notable example of authentication systems utilizing a trusted third party, and it is implemented in most major operating systems such as Microsoft Windows, and systems running Unix such as OS X and Ubuntu. In \gls{ieee} 802.11, which is the standard for \gls{wlan} communication networks, protocols such as \gls{wpa} and \gls{wpa2} may utilize the \gls{eap} as their authentication framework, which provides methods for negotiating multiple different key establishment and authentication schemes.


\subsubsection{Public-Key}

Of the different public-key cryptosystems in use today, the \gls{rsa} cryptosystem is the most commonly used, which provides key generation, key exchange, and authentication \cite{wander2005energy}. \gls{rsa} is not that often used for actually encrypt data sent between two parties as it is a relatively slow algorithm. Therefore, it is more convenient to encrypt a shared symmetric key under the parties' public keys to use for encryption of data. \gls{rsa} provides authentication, while other properties involving session keys rely on the protocol used for establishing such keys. The ElGamal cryptosystem, which is based on the Diffie-Hellman key exchange, is another example of a system that is usually operated as a hybrid system utilizing both symmetric keys (for encryption) and public-key cryptography (for establishing symmetric keys). 

\gls{ecc} systems utilize the algebraic structure of elliptic curves over finite fields, and can be used to both generate asymmetric key pairs and digital signatures, as well as providing key establishment \cite{bos2014elliptic}. \gls{ecdh}, which is also based upon the Diffie-Hellman key exchange is, perhaps, the most notable scheme. One of the benefits with \gls{ecc} over more commonly used public-key algorithms such as \gls{rsa} is the reduced key size, which leads to greater memory and energy savings, while providing approximate the same level of security (\gls{ecc}-160, which has a key size of 160 bits, is equivalent to \gls{rsa}-1024 in terms of cryptographic strength) \cite{nist2016}. When operating in a mode that uses \emph{ephemeral} keys, which are temporary keys generated in a key establishment process, \gls{ecdh} provides security properties such as key control, known-key security, and forward secrecy. \gls{ecdh} does not, however, provide authentication, which has to be addressed separately for example by using the \gls{ecdsa}. 

% MQV - UKS and KCI


\subsection{Key Establishment Schemes in Wireless Sensor Networks and the Internet of Things}

When it comes to \gls{wsn} applications, symmetric encryption algorithms have historically been the most mature ones \citep{Jing2014}. Sensor nodes running \gls{6lowpan} are powerful enough to implement cryptography standards such as \gls{aes}-128, providing such nodes with a satisfying level of encryption \cite{Roman2011147}. However, there exists several drawbacks with technology utilizing symmetric encryption. For starters, their key exchange protocols are often complex, which is a constraint for the scalability of the network. Also, as the \gls{iot} devices are placed in possible hostile environment, they may be physically tampered with by adversaries \cite{krentz20136lowpan}. If they should successfully compromise one of the nodes, then the security of the entire network may be at stake. Finally, authentication is a rather complex and inconvenient procedure with symmetric encryption involving \gls{mac-auth}s, which leads to higher requirements for storage space, overhead in messages, and increased energy consumption.

Based on these issues, the research community looked to public-key cryptography, which had previously been considered  an unsuitable solution for key establishment and key management in \gls{wsn}s and other \gls{iot} related networks \cite{gaubatz2004public, wander2005energy}. While improving the security over symmetric key encryption, and also providing easier authentication and higher scalability, regular public-key protocols have issues related to energy consumption due to higher computational complexity, as well as being significantly more time consuming \cite{Eschenauer2002}. However, computer hardware specifications improves on a yearly basis, as more transistors are placed on data chips, and the processors are becoming more powerful and energy efficient. Public-key cryptography algorithms such as Rabin's Scheme, NtruEncrypt and \gls{ecc} all have proven promising results when implemented efficiently for wireless platforms \cite{Jing2014}, and especially \gls{ecc} and its implementation of \gls{ecdsa} have reduced the time spent on constructing a digital signature from 34 seconds in 2005, to 0.5 seconds in 2009 \cite{Roman2011147}. There is not, however, any current scheme that provides a clear advantage over others, symmetric or asymmetric, as they all have different advantages and disadvantages. 

%Bottom line, there is currently no scheme that provides a clear advantage over others, symmetric or asymmetric, as they all have different advantages and disadvantages. It is up to the application designer to find and implement the best suited scheme based on the infrastructure, available resources, and security demands of the particular network. 


%It has previously been an underlying assumption in the research community that public-key cryptography has been an unsuitable solution for key establishment and key management in \gls{wsn}s and other \gls{iot} related networks \cite{gaubatz2004public, wander2005energy}. While improving the security over symmetric key encryption, and also providing easier authentication and higher scalability, regular public-key protocols have issues related to energy consumption due to higher computational complexity as well as being significantly more time consuming \citep{Eschenauer2002}. Computer hardware specifications improves for every year, more transistors are placed on data chips, and the processors are becoming more energy efficient. Public-key cryptography algorithms such as Rabin's Scheme, NtruEncrypt and \gls{ecc} have proven promising results when implemented efficiently for wireless platforms \cite{gaubatz2004public, Jing2014}, and especially \gls{ecc} and its implementation of \gls{ecdsa} have proven to be over four times more energy efficient than \gls{rsa}-1024 \cite{wander2005energy}. 

Following the line of thought where hardware specifications continuously improve, devices are also getting smaller as new ``doors'' are opened based on the accessibility of better hardware. Currently, companies such as Samsung and Sony are filing patents for so-called ``smart'' contact lenses, which are allegedly capable of taking pictures of the user's current view, and transmitting the data wirelessly to another device \cite{sony-lens, samsung-lens}. Processing units on something as small as a contact lens, which has to be transparent and not ``bulky'' to provide minimum distress on the eye, introduces a whole new level of demands to the energy efficiency of the components. As the data that is transferred from the lens obviously has to be secured in some way (having your ``eyes'' hacked does not sound especially tempting), we can only assume that the concept of symmetric key establishment is something that will be relevant in the distant future. Therefore, the rest of this thesis will have a special focus on symmetric key establishment.



\section{Formal Security Analysis} 
\label{sec:formal}

As security protocols grow larger and more complex, they become more and more difficult for humans to analyse. One of the examples of the need for formal security analysis is the Needham-Schroeder Public-Key Protocol from 1978 \cite{Needham:1978}. The Needham-Schroeder Public-Key Protocol is based on public-key cryptography and was intended to allow two communicating parties to mutually authenticate each other. Throughout this section, the protocol (referred to as the Needham-Schroeder protocol) will be used as an illustrative example to underline the importance of formal security analysis.

One of the pioneering works on security analysis was conducted by Burrows, Abadi and Needham with their \gls{ban} logic. \gls{ban} logic is a set of rules which can be used to determine whether received information is trustworthy or not, by formally describing the interaction between communicating parties \cite{burrows1989logic}. It showed promising results in finding security flaws and drawbacks for several authentication protocols, but was later abandoned due to the fact that it verified insecure protocols as secure, and in some cases perfectly sound protocols to be insecure \cite{boyd1993}. One of the protocols that was formally verified using \gls{ban} logic was the Needham-Schroeder protocol.

In fact, 17 years later after being deployed and widely used, Lowe discovered using the automatic tool Casper that the Needham-Schroeder protocol was insecure, and vulnerable to a man-in-the-middle attack \cite{basin2011model, lowe1996}. The discovery of that such a flaw had gone unnoticed for so many years puzzled the research community, leading to an increased interest in formal security analysis \cite{cremers2009comparing}. Researchers started developing tools for exhaustive search of the problem space of a protocol in order to detect possible abnormalities in protocol behaviour. 


% Kanskje litt mer her.

In order to conduct formal security analysis, we need a formal model to be able to study the protocol under precise assumptions. Formal security models are abstractions of descriptions of systems, aiming to improve the understanding of the security of the system by simplifying its interpretation. Models can be defined into two different groups: Computational and symbolic models. Computational models are detailed and cryptographic, while symbolic models are more abstract and simple.

By defining a formal security model, we aim to discover and correct errors, incompleteness and inconsistencies in protocol specifications, before they are exploited by adversaries. A protocol specification is a description of the behaviour of the different entities that are allowed to communicate with each other during an execution of the protocol \cite{cremers2005operational}. More precise, a protocol description specifies the different roles in the protocol, each containing a sequential list of the messages that are sent and received from that particular role. It also contains the information of the initial knowledge of the protocol, which are the functions, constants and variables that the protocol needs to execute correctly. Such a specification is expressed using a formal language, which has well-defined syntax and semantics, for example process algebra, predicate logic, and lambda calculus. 

Computational models are another way of mathematically model security protocols, mainly used by cryptographers, hence it holds a more mathematical approach compared to the symbolic model, and is also said to be more realistic and detailed. Messages are represented as bitstrings, which are sent into cryptographic primitives (can be seen as ``functions'') where they are computed on bit-by-bit, and come out as bitstrings \cite{blanchet2012security}. Adversaries in computational models are modelled as powerful arbitrary and probabilistic Turing machines. They do not, however, account for physical attacks such as side-channel analysis and fault attacks, which may be more important as the device-to-device communication increases in the future. Security proofs offered by computational models are often acknowledged as powerful, but often difficult, long, and prone to errors \cite{cortier2011survey}. For constructing proofs, symbolic models are much more efficient as they can more easier be automated to explore the entire problem space.

% Intruder model

The Dolev-Yao model is a symbolic and formal intruder model used to prove the security properties of cryptographic protocols. Symbolic analysis considers cryptographic primitives as ``black boxes'' based on the assumption of perfect cryptography. The black boxes are used to construct terms, which represents the computational operations that the adversary is allowed to perform \cite{blanchet2012security}. While initially being a verification model built for public key protocols, the Dolev-Yao model is also the basis for most of the security analysis done by verification tools that focus on verifying secrecy and authentication properties \cite{cremers2005operational}. The model is built upon three primary assumptions: Perfect cryptography, complete control of network, and abstract terms \cite{dolev1983security}. Firstly, the Dolev-Yao model assumes that the cryptography is perfect, essentially meaning that the cryptographic system can not be tampered with, and an encrypted message can only be decrypted by the party possessing the corresponding decryption key. The second assumption is that the adversary has complete control over the communication network, hence he is able to observe all messages that are sent between communicating parties, and can inject messages given that he is able to forge its content in a valid matter. Lastly, messages that are sent in the network are to be observed as abstract terms, where the attacker has two possible outcomes: Either he learns the complete content of the message, or he learns nothing at all. 

% Verification and falsification

Falsification, presented by Popper in 1934, is the theory of presenting an observation that would disprove the correctness of an alleged theory, or more informally; It is not possible to prove a theory from a single correct observation, but a single observation that contradicts the theory is enough to disprove it \cite{popper2005logic}. The falsification process in model checking is to formally assess the security properties of the protocol in order to discover examples that disproves the claimed security by constructing counter-examples. Following in the same line of thoughts, we can perform verification by using formal models and languages to verify a statement (i.e. a security property). In formal security analysis, this is referred to as model checking, which uses the formal model to exhaustively verify whether it meets the alleged security properties \cite{basin2011model}. Verification can also be done by constructing mathematical proofs for each of the security properties, proving that the alleged security property is fulfilled. 



% Nevne at grunnen til formell sikkerhetsanalyse er at man ikke vet hva slags security properties en protocol hevder  ha

\section{Related Work}

Over the last decade, formal security analysis using tools have been more popular, and there exists numerous examples of key establishment protocols that have been formally verified using tools such as Scyther.

One of the pioneers on formal security analysis is the author of the Scyther tool, Cas Cremers, which has formally verified multiple protocols such as the \gls{ike} protocols \gls{ike}v1 and \gls{ike}v2 \cite{Cremers2011}. In addition to these, Cremers and Horvat performed formal security analysis of the proposed protocols in the ISO/IEC 11770 standard \cite{cremers2014improving}, where they discovered unreported weaknesses in the protocols related to authentication. There exists several analyses involving \gls{ake} protocols which use a stronger adversary than what the regular Dolev-Yao model provides, where protocols such as Yahalom, HMQV, DH-ISO and Naxos are verified in \cite{cremers2009comparing}. 


This thesis focuses on key management protocols for wireless networks such as the \gls{ieee} 802.15.4 standard. The \gls{ieee} 802.16e standard, also known as WiMAX, has been formally analysed in \cite{andova2008framework}. Key establishment schemes targeted on 802.15.4 networks, and especially \gls{6lowpan}, have not been the focus of formal security analysis. As the requirements for key establishment schemes in \gls{wsn}s differs from well-known standards such as 802.11 and WiMAX, the focus of such schemes has been more of efficiency and usability with respect to energy and complexity, rather than verifying that they are secure for all possible scenarios.

% Finne NOE formell analyse av key establishment schemes for 6lowpan.
